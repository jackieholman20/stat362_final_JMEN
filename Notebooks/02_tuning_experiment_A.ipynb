{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zfkwuu2uT27i","outputId":"05b005b5-24a8-429c-d321-735a011c3968"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/2.4 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hMounted at /content/drive\n","device: cuda\n","gpu: Tesla T4\n","total: 26684\n","target\n","2    11821\n","0     8851\n","1     6012\n","Name: count, dtype: int64\n","Train: 18678, Val: 4003, Test: 4003\n","batch: torch.Size([32, 3, 320, 320]) torch.Size([32])\n","Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 30.8M/30.8M [00:00<00:00, 165MB/s]\n","train 1/15: 100%|██████████| 584/584 [10:09<00:00,  1.04s/it, loss=0.966]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["epoch 1 train_loss 0.8282 train_acc 0.4942 val_loss 0.7073 val_acc 0.6605 val_bal 0.7000\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["train 2/15: 100%|██████████| 584/584 [09:17<00:00,  1.05it/s, loss=0.695]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["epoch 2 train_loss 0.7791 train_acc 0.5271 val_loss 0.6782 val_acc 0.7110 val_bal 0.7275\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["train 3/15: 100%|██████████| 584/584 [09:19<00:00,  1.04it/s, loss=0.63]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["epoch 3 train_loss 0.7587 train_acc 0.5259 val_loss 0.6950 val_acc 0.6920 val_bal 0.7218\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["train 4/15: 100%|██████████| 584/584 [09:14<00:00,  1.05it/s, loss=0.615]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["epoch 4 train_loss 0.7461 train_acc 0.5314 val_loss 0.6966 val_acc 0.6787 val_bal 0.7161\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["train 5/15: 100%|██████████| 584/584 [09:17<00:00,  1.05it/s, loss=0.548]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["epoch 5 train_loss 0.7131 train_acc 0.5377 val_loss 0.6757 val_acc 0.7292 val_bal 0.7310\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["train 6/15: 100%|██████████| 584/584 [09:14<00:00,  1.05it/s, loss=1.05]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["epoch 6 train_loss 0.7029 train_acc 0.5645 val_loss 0.6668 val_acc 0.7332 val_bal 0.7324\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["train 7/15: 100%|██████████| 584/584 [09:16<00:00,  1.05it/s, loss=0.62]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["epoch 7 train_loss 0.6888 train_acc 0.5661 val_loss 0.6710 val_acc 0.6970 val_bal 0.7222\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["train 8/15: 100%|██████████| 584/584 [09:14<00:00,  1.05it/s, loss=0.611]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["epoch 8 train_loss 0.6874 train_acc 0.5529 val_loss 0.6778 val_acc 0.7280 val_bal 0.7337\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["train 9/15: 100%|██████████| 584/584 [09:13<00:00,  1.05it/s, loss=0.406]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["epoch 9 train_loss 0.6719 train_acc 0.5520 val_loss 0.6753 val_acc 0.7277 val_bal 0.7349\n"]},{"output_type":"stream","name":"stderr","text":["train 10/15:  63%|██████▎   | 369/584 [05:52<03:10,  1.13it/s, loss=0.487]"]}],"source":["# install + mount\n","!pip -q install pydicom\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n","\n","# paths\n","import os\n","base = \"/content/drive/MyDrive/STAT362 Final Project_RSNA\"\n","zip_path = f\"{base}/images.zip\"\n","out_dir = \"/content/train_images\"\n","img_dir = f\"{out_dir}/stage_2_train_images\"\n","\n","# unzip\n","!mkdir -p /content/train_images\n","!unzip -n -q \"{zip_path}\" -d \"{out_dir}\"\n","\n","# imports\n","import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import pydicom\n","from PIL import Image\n","import torchvision.transforms as transforms\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, confusion_matrix, balanced_accuracy_score\n","from tqdm import tqdm\n","import copy\n","from torchvision.models import densenet121, DenseNet121_Weights\n","\n","# apply_voi_lut import (pydicom v3 vs newer)\n","try:\n","    from pydicom.pixels import apply_voi_lut\n","except Exception:\n","    from pydicom.pixel_data_handlers.util import apply_voi_lut\n","\n","# device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","use_cuda = torch.cuda.is_available()\n","print(\"device:\", device)\n","if use_cuda:\n","    print(\"gpu:\", torch.cuda.get_device_name(0))\n","torch.backends.cudnn.benchmark = True\n","\n","# load csv\n","detailed_class = pd.read_csv(f\"{base}/stage_2_detailed_class_info.csv\")\n","labels = pd.read_csv(f\"{base}/stage_2_train_labels.csv\")\n","\n","# process labels\n","detailed_class = detailed_class.drop_duplicates(subset=[\"patientId\"])\n","class_mapping = {\"Normal\": 0, \"Lung Opacity\": 1, \"No Lung Opacity / Not Normal\": 2}\n","detailed_class[\"target\"] = detailed_class[\"class\"].map(class_mapping)\n","detailed_class[\"path\"] = detailed_class[\"patientId\"].apply(lambda x: f\"{img_dir}/{x}.dcm\")\n","print(\"total:\", len(detailed_class))\n","print(detailed_class[\"target\"].value_counts())\n","\n","# dataset\n","class RSNADataset(Dataset):\n","    def __init__(self, dataframe, transform=None):\n","        self.df = dataframe.reset_index(drop=True)\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.df.loc[idx, \"path\"]\n","        label = int(self.df.loc[idx, \"target\"])\n","\n","        ds = pydicom.dcmread(img_path)\n","        img = ds.pixel_array.astype(np.float32)\n","\n","        try:\n","            img = apply_voi_lut(img, ds).astype(np.float32)\n","        except Exception:\n","            pass\n","\n","        if getattr(ds, \"PhotometricInterpretation\", \"\") == \"MONOCHROME1\":\n","            img = img.max() - img\n","\n","        lo, hi = np.percentile(img, (1, 99))\n","        img = np.clip(img, lo, hi)\n","        img = (img - lo) / (hi - lo + 1e-6)\n","\n","        img = (img * 255.0).astype(np.uint8)\n","        image = Image.fromarray(img).convert(\"RGB\")\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, torch.tensor(label, dtype=torch.long)\n","\n","# transforms\n","IMG_SIZE = 320\n","\n","train_transforms = transforms.Compose([\n","    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.85, 1.0), ratio=(0.9, 1.1)),\n","    transforms.RandomHorizontalFlip(p=0.5),\n","    transforms.RandomRotation(10),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","eval_transforms = transforms.Compose([\n","    transforms.Resize(int(IMG_SIZE * 1.1)),\n","    transforms.CenterCrop(IMG_SIZE),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","# split\n","train_df, temp_df = train_test_split(\n","    detailed_class, test_size=0.3, stratify=detailed_class[\"target\"], random_state=42\n",")\n","val_df, test_df = train_test_split(\n","    temp_df, test_size=0.5, stratify=temp_df[\"target\"], random_state=42\n",")\n","print(f\"Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")\n","\n","# loaders\n","BATCH_SIZE = 32\n","NUM_WORKERS = 2  # set to 0 if DataLoader workers crash\n","\n","train_dataset = RSNADataset(train_df, transform=train_transforms)\n","val_dataset   = RSNADataset(val_df,   transform=eval_transforms)\n","test_dataset  = RSNADataset(test_df,  transform=eval_transforms)\n","\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n","                          num_workers=NUM_WORKERS, pin_memory=use_cuda)\n","val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False,\n","                          num_workers=NUM_WORKERS, pin_memory=use_cuda)\n","test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False,\n","                          num_workers=NUM_WORKERS, pin_memory=use_cuda)\n","\n","x0, y0 = next(iter(train_loader))\n","print(\"batch:\", x0.shape, y0.shape)\n","\n","# model\n","model = densenet121(weights=DenseNet121_Weights.DEFAULT)\n","nf = model.classifier.in_features\n","model.classifier = nn.Sequential(\n","    nn.Linear(nf, 512),\n","    nn.ReLU(),\n","    nn.Dropout(0.4),\n","    nn.Linear(512, 3),\n",")\n","model = model.to(device)\n","\n","# loss (class weights + label smoothing)\n","class_counts = train_df[\"target\"].value_counts().sort_index().values\n","class_weights = 1.0 / torch.tensor(class_counts, dtype=torch.float32)\n","class_weights = (class_weights / class_weights.sum()) * len(class_counts)\n","criterion = nn.CrossEntropyLoss(weight=class_weights.to(device), label_smoothing=0.05)\n","\n","# optimizer + scheduler\n","optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.5, patience=1)\n","\n","# amp\n","scaler = torch.amp.GradScaler(\"cuda\") if use_cuda else None\n","\n","# mixup\n","def mixup(x, y, alpha=0.2):\n","    if alpha <= 0:\n","        return x, y, y, 1.0\n","    lam = np.random.beta(alpha, alpha)\n","    idx = torch.randperm(x.size(0), device=x.device)\n","    x2 = lam * x + (1 - lam) * x[idx]\n","    y_a, y_b = y, y[idx]\n","    return x2, y_a, y_b, lam\n","\n","# train\n","num_epochs = 15\n","patience = 4\n","best_val_bal = -1.0\n","best_state = None\n","no_improve = 0\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    tr_loss = 0.0\n","    tr_total = 0\n","    tr_correct = 0\n","\n","    loop = tqdm(train_loader, desc=f\"train {epoch+1}/{num_epochs}\")\n","    for x, y in loop:\n","        x = x.to(device, non_blocking=True)\n","        y = y.to(device, non_blocking=True)\n","\n","        x, y_a, y_b, lam = mixup(x, y, alpha=0.2)\n","\n","        optimizer.zero_grad(set_to_none=True)\n","\n","        if use_cuda:\n","            with torch.amp.autocast(\"cuda\"):\n","                out = model(x)\n","                loss = lam * criterion(out, y_a) + (1 - lam) * criterion(out, y_b)\n","            scaler.scale(loss).backward()\n","            scaler.step(optimizer)\n","            scaler.update()\n","        else:\n","            out = model(x)\n","            loss = lam * criterion(out, y_a) + (1 - lam) * criterion(out, y_b)\n","            loss.backward()\n","            optimizer.step()\n","\n","        tr_loss += loss.item() * x.size(0)\n","        tr_total += y.size(0)\n","        tr_correct += (out.argmax(1) == y).sum().item()\n","        loop.set_postfix(loss=float(loss.item()))\n","\n","    tr_loss /= tr_total\n","    tr_acc = tr_correct / tr_total\n","\n","    model.eval()\n","    va_loss = 0.0\n","    va_total = 0\n","    va_preds = []\n","    va_labels = []\n","\n","    with torch.no_grad():\n","        for x, y in val_loader:\n","            x = x.to(device, non_blocking=True)\n","            y = y.to(device, non_blocking=True)\n","\n","            if use_cuda:\n","                with torch.amp.autocast(\"cuda\"):\n","                    out = model(x)\n","                    loss = criterion(out, y)\n","            else:\n","                out = model(x)\n","                loss = criterion(out, y)\n","\n","            va_loss += loss.item() * x.size(0)\n","            va_total += y.size(0)\n","\n","            va_preds.append(out.argmax(1).cpu().numpy())\n","            va_labels.append(y.cpu().numpy())\n","\n","    va_loss /= va_total\n","    va_preds = np.concatenate(va_preds)\n","    va_labels = np.concatenate(va_labels)\n","\n","    va_acc = (va_preds == va_labels).mean()\n","    va_bal = balanced_accuracy_score(va_labels, va_preds)\n","\n","    scheduler.step(va_bal)\n","\n","    print(f\"epoch {epoch+1} train_loss {tr_loss:.4f} train_acc {tr_acc:.4f} val_loss {va_loss:.4f} val_acc {va_acc:.4f} val_bal {va_bal:.4f}\")\n","\n","    if va_bal > best_val_bal:\n","        best_val_bal = va_bal\n","        best_state = copy.deepcopy(model.state_dict())\n","        no_improve = 0\n","    else:\n","        no_improve += 1\n","\n","    if no_improve >= patience:\n","        print(\"early stop\")\n","        break\n","\n","if best_state is not None:\n","    model.load_state_dict(best_state)\n","print(\"best val_bal:\", best_val_bal)\n","\n","# test\n","model.eval()\n","te_loss = 0.0\n","te_total = 0\n","te_preds = []\n","te_labels = []\n","\n","with torch.no_grad():\n","    for x, y in test_loader:\n","        x = x.to(device, non_blocking=True)\n","        y = y.to(device, non_blocking=True)\n","\n","        if use_cuda:\n","            with torch.amp.autocast(\"cuda\"):\n","                out = model(x)\n","                loss = criterion(out, y)\n","        else:\n","            out = model(x)\n","            loss = criterion(out, y)\n","\n","        te_loss += loss.item() * x.size(0)\n","        te_total += y.size(0)\n","\n","        te_preds.append(out.argmax(1).cpu().numpy())\n","        te_labels.append(y.cpu().numpy())\n","\n","te_loss /= te_total\n","te_preds = np.concatenate(te_preds)\n","te_labels = np.concatenate(te_labels)\n","\n","te_acc = (te_preds == te_labels).mean()\n","te_bal = balanced_accuracy_score(te_labels, te_preds)\n","cm = confusion_matrix(te_labels, te_preds)\n","\n","print(\"test_loss:\", round(float(te_loss), 4))\n","print(\"test_acc:\", round(float(te_acc), 4))\n","print(\"test_balanced_acc:\", round(float(te_bal), 4))\n","print(\"confusion_matrix:\\n\", cm)\n","print(\"\\nclassification_report:\\n\", classification_report(te_labels, te_preds, digits=4))\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[{"file_id":"1rLUeQw0L5byxIw-7v2dj4_MIoZJn6jzk","timestamp":1764883390985}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}